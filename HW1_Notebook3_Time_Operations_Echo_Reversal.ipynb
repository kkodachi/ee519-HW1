{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add5441d",
   "metadata": {},
   "source": [
    "# EE 519 — Speech AI \n",
    "## HW-1 | Notebook 3: Time Operations — Delay, Echo, Reversal (Global & Short-Time)\n",
    "\n",
    "**Student Name:**  \n",
    "**USC ID:**  \n",
    "**Date:**  \n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "By completing this notebook, you will:\n",
    "- Apply **time-domain operations** to speech (delay, echo, reversal)\n",
    "- Connect time operations to perceptual effects (echo vs reverb-like smear)\n",
    "- Compare **global time reversal** vs **short-time reversal**\n",
    "- Develop intuition for **short-time processing** and (approx.) stationarity in speech\n",
    "\n",
    "> ⚠️ **Important**\n",
    "> - All answers (code + explanations) must be written **inside this notebook**\n",
    "> - Do **not** delete questions or prompts\n",
    "> - Clearly label all plots (title, axes, units)\n",
    "> - Audio must be playable inline where requested\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e68697",
   "metadata": {},
   "source": [
    "### Grading (Notebook 3 — 20 points)\n",
    "\n",
    "| Component | Points |\n",
    "|---|---:|\n",
    "| Reproducible audio setup + clean I/O | 3 |\n",
    "| Delay + echo experiments (plots + listening) | 6 |\n",
    "| Global reversal analysis (plots + explanation) | 4 |\n",
    "| Short-time reversal analysis (plots + explanation) | 5 |\n",
    "| Clarity, organization, reflections | 2 |\n",
    "\n",
    "> We grade **understanding and reasoning**, not perfection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ffffd8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 0. Setup\n",
    "\n",
    "This notebook must run **quickly and reproducibly** for grading.\n",
    "\n",
    "## ✅ Reproducibility requirements (very important)\n",
    "- Put audio files in the **same folder as this notebook** or inside `./audio/`\n",
    "- Use **relative paths only**\n",
    "- Do not rely on cloud mounts or absolute paths\n",
    "- Notebook should run top-to-bottom after we download your ZIP\n",
    "\n",
    "Recommended structure:\n",
    "```\n",
    "HW1/\n",
    "├── HW1_Notebook3_Time_Operations_Echo_Reversal.ipynb\n",
    "└── audio/\n",
    "    └── x.wav\n",
    "```\n",
    "\n",
    "## Data requirement\n",
    "You need **one** speech recording `x` (sentence recommended).\n",
    "You may:\n",
    "- Record it in Python (optional) and save to `./audio/x.wav`, OR\n",
    "- Record externally and place it at `./audio/x.wav`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4387f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Path (use relative paths only)\n",
    "X_PATH = \"./audio/x.wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25689c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL recording (only if your system supports it):\n",
    "# If recording doesn't work, skip this and use an external WAV file.\n",
    "#\n",
    "# !pip install sounddevice soundfile  # (uncomment if needed/allowed)\n",
    "# import sounddevice as sd\n",
    "# import soundfile as sf\n",
    "# from pathlib import Path\n",
    "#\n",
    "# Path(\"./audio\").mkdir(exist_ok=True)\n",
    "# fs_rec = 16000\n",
    "# duration_sec = 5\n",
    "# print(\"Recording... Speak your sentence now.\")\n",
    "# x = sd.rec(int(duration_sec*fs_rec), samplerate=fs_rec, channels=1)\n",
    "# sd.wait()\n",
    "# x = x.squeeze()\n",
    "# sf.write(\"./audio/x.wav\", x, fs_rec)\n",
    "# print(\"Saved to ./audio/x.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7e4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement or reuse WAV loader (mono float in [-1, 1])\n",
    "def load_wav(path):\n",
    "    raise NotImplementedError(\"Implement load_wav(path)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07298e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load signal\n",
    "# x, fs = load_wav(X_PATH)\n",
    "# print(fs, len(x)/fs, x.min(), x.max())\n",
    "# display(Audio(x, rate=fs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f3b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Helper functions\n",
    "def plot_waveform(x, fs, title, tlim=None):\n",
    "    raise NotImplementedError\n",
    "\n",
    "def play_audio(x, fs):\n",
    "    display(Audio(x, rate=fs))\n",
    "\n",
    "def magnitude_spectrum(x, fs):\n",
    "    \"\"\"Return f (Hz) and magnitude (dB or linear).\"\"\"\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f68f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Time Delay and Echo (Single-Tap FIR Intuition)\n",
    "\n",
    "An **echo** can be created by adding a delayed and scaled copy of the signal:\n",
    "\n",
    "\\[\n",
    "y[n] = x[n] + \\alpha x[n-D]\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\(D\\) is the delay in samples (e.g., 50 ms, 100 ms, 300 ms)\n",
    "- \\(\\alpha\\) is the echo gain (e.g., 0.2–0.7)\n",
    "\n",
    "### Task\n",
    "Create echoes with delays:\n",
    "- 50 ms\n",
    "- 100 ms\n",
    "- 300 ms\n",
    "\n",
    "For each delay, test at least **two** gains (e.g., 0.3 and 0.6).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115de3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement delay operator\n",
    "def delay_signal(x, D):\n",
    "    \"\"\"Delay by D samples: y[n] = x[n-D] with zero padding.\"\"\"\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement echo creator\n",
    "def add_echo(x, fs, delay_ms, alpha):\n",
    "    \"\"\"Return echoed signal y = x + alpha * delayed(x).\"\"\"\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94663f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run echo experiments\n",
    "# delays_ms = [50, 100, 300]\n",
    "# alphas = [0.3, 0.6]\n",
    "# results = {}  # e.g., results[(delay_ms, alpha)] = y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757763b",
   "metadata": {},
   "source": [
    "## 1.1 Visualize echoes\n",
    "\n",
    "For at least one region containing speech:\n",
    "- Plot original and echoed signal (overlay) for each condition\n",
    "- Use the same time window for fair comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot overlays for echo conditions\n",
    "# Pick a time window: (t_start, t_end)\n",
    "# plot_waveform(x, fs, \"Original\", tlim=(..., ...))\n",
    "# for (delay_ms, alpha), y in results.items():\n",
    "#     plot_waveform(y, fs, f\"Echo: {delay_ms}ms, alpha={alpha}\", tlim=(..., ...))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc7e16",
   "metadata": {},
   "source": [
    "## 1.2 Listen: echo vs reverb-like smear\n",
    "\n",
    "Play each echoed version and describe:\n",
    "- When does the echo become a distinct repetition?\n",
    "- When does it feel like “thickening”/reverberation instead?\n",
    "\n",
    "> Use headphones if possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a82d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Listening test\n",
    "# for (delay_ms, alpha), y in results.items():\n",
    "#     print(f\"Echo: {delay_ms} ms, alpha={alpha}\")\n",
    "#     play_audio(y, fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def3d2ec",
   "metadata": {},
   "source": [
    "### Observations (Echo)\n",
    "\n",
    "Answer in 8–12 lines total:\n",
    "\n",
    "- Which delay/gain combination sounded like a **distinct echo**?\n",
    "- Which combinations sounded more like **reverb / thickening**?\n",
    "- What role does \\(\\alpha\\) play perceptually?\n",
    "- Did any condition cause clipping? If yes, how did you handle it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73832ed6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Global Time Reversal\n",
    "\n",
    "Global time reversal is:\n",
    "\\[\n",
    "y[n] = x[-n]\n",
    "\\]\n",
    "In discrete time (finite signals), reversing the array implements this.\n",
    "\n",
    "### Task\n",
    "- Create a fully time-reversed version of your speech signal\n",
    "- Compare waveform, spectrum, and intelligibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676a07b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Global reversal\n",
    "# y_rev = x[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac9c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot + play global reversal\n",
    "# plot_waveform(x, fs, \"Original (full)\")\n",
    "# plot_waveform(y_rev, fs, \"Global time reversal (full)\")\n",
    "# play_audio(y_rev, fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa866ca3",
   "metadata": {},
   "source": [
    "### Conceptual Questions (Global Reversal)\n",
    "\n",
    "Answer clearly in complete sentences:\n",
    "\n",
    "1. Is the reversed speech intelligible? Why or why not?  \n",
    "2. Which properties remain the same after reversal (duration, energy distribution, magnitude spectrum)?  \n",
    "3. Which properties fundamentally change (temporal cues, attack/decay patterns, coarticulation cues)?  \n",
    "4. Does the **magnitude spectrum** change under reversal? (Explain.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd8ef5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Short-Time Reversal (Windowed / Local Reversal)\n",
    "\n",
    "In short-time processing, we operate on short frames (e.g., 20–30 ms).\n",
    "Short-time reversal reverses samples **within each frame**, while frame order remains unchanged.\n",
    "\n",
    "### Task\n",
    "Implement short-time reversal with:\n",
    "- 20 ms frames\n",
    "- 30 ms frames\n",
    "Use a hop size equal to the frame size (non-overlapping) for simplicity.\n",
    "\n",
    "> Optional extension: try overlapping frames with a window and overlap-add.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bf24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement short-time reversal\n",
    "def short_time_reverse(x, fs, frame_ms):\n",
    "    \"\"\"Reverse samples within each frame of length frame_ms (non-overlapping).\"\"\"\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate short-time reversed signals\n",
    "# y_str_20 = short_time_reverse(x, fs, frame_ms=20)\n",
    "# y_str_30 = short_time_reverse(x, fs, frame_ms=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58bc747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot + play short-time reversal outputs\n",
    "# play_audio(y_str_20, fs)\n",
    "# play_audio(y_str_30, fs)\n",
    "# Plot a segment for comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058021be",
   "metadata": {},
   "source": [
    "## 3.1 Spectrogram comparison (recommended)\n",
    "\n",
    "Compute and plot spectrograms for:\n",
    "- Original\n",
    "- Global reversal\n",
    "- 20 ms short-time reversal\n",
    "- 30 ms short-time reversal\n",
    "\n",
    "Use consistent STFT parameters (e.g., 25 ms window, 10 ms hop) for display.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a spectrogram helper (STFT magnitude)\n",
    "def plot_spectrogram(x, fs, title, n_fft=1024, win_ms=25, hop_ms=10):\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a72cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot spectrograms (4 figures)\n",
    "# plot_spectrogram(x, fs, \"Original\")\n",
    "# plot_spectrogram(y_rev, fs, \"Global reversal\")\n",
    "# plot_spectrogram(y_str_20, fs, \"Short-time reversal: 20 ms\")\n",
    "# plot_spectrogram(y_str_30, fs, \"Short-time reversal: 30 ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba29c88",
   "metadata": {},
   "source": [
    "### Observations (Short-Time Reversal)\n",
    "\n",
    "Answer in 10–14 lines total:\n",
    "\n",
    "- Which is more intelligible: 20 ms or 30 ms short-time reversal? Why?\n",
    "- Why is short-time reversal often **less destructive** than global reversal?\n",
    "- What does this reveal about speech being “locally stationary” over short frames?\n",
    "- What changed in the spectrograms vs the original?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f2098a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Connecting to Short-Time Processing Intuition\n",
    "\n",
    "Write 8–12 lines:\n",
    "\n",
    "- Why do we process speech in short frames (20–30 ms)?\n",
    "- What assumptions are we making about speech within a frame?\n",
    "- How did your reversal experiments support or challenge those assumptions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e342a0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Reflection (Mandatory)\n",
    "\n",
    "Write thoughtful answers (be specific):\n",
    "\n",
    "1. What did you learn that you did not expect about **delay/echo**?  \n",
    "2. What was one surprising perceptual effect you noticed?  \n",
    "3. Which visualization (waveform vs spectrogram) helped you explain what you heard—and why?  \n",
    "4. If you had to explain “short-time processing” to a friend in 2–3 sentences, what would you say?  \n",
    "5. What experiment would you try next (e.g., multiple echoes, feedback echo, overlap-add short-time reversal)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b81ab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. AI Use Disclosure (Required)\n",
    "\n",
    "If you used any AI tools (including ChatGPT), briefly describe:\n",
    "- What you used it for (e.g., debugging, concept clarification)\n",
    "- What you wrote/changed yourself\n",
    "\n",
    "*(If you did not use AI, write “No AI tools used.”)*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
