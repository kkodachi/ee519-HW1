{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f226d35d",
   "metadata": {},
   "source": [
    "# EE 519 — Speech AI\n",
    "## HW-1 | Notebook 5: Speech Production, Sound Categories, Segmentation, Variability\n",
    "\n",
    "**Student Name:**  \n",
    "**USC ID:**  \n",
    "**Date:**  \n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "By completing this notebook, you will:\n",
    "- Practice recording and analyzing **speech sounds** (vowels, consonants)\n",
    "- Connect **speech production** (voicing, place/manner) to signal patterns\n",
    "- Perform **basic segmentation**: words → syllables → phones (approx.)\n",
    "- Study **variability** across repeated recordings and speakers\n",
    "- Identify **coarticulation** in real speech using waveform + spectrogram + listening\n",
    "\n",
    "> ⚠️ **Important**\n",
    "> - All answers (code + explanations) must be written **inside this notebook**\n",
    "> - Do **not** delete questions or prompts\n",
    "> - Clearly label all plots (title, axes, units)\n",
    "> - Use **relative paths only** and keep audio under `./audio/` for grading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f7eaaf",
   "metadata": {},
   "source": [
    "### Grading (Notebook 5 — 20 points)\n",
    "\n",
    "| Component | Points |\n",
    "|---|---:|\n",
    "| Recording/collection of required sounds + clean organization | 4 |\n",
    "| Variability analysis (same speaker repeats + multi-speaker) | 5 |\n",
    "| Segmentation (words/syllables/phones) with evidence | 6 |\n",
    "| Speech production explanations (voiced/voiceless, manner/place cues) | 3 |\n",
    "| Clarity, structure, reflections | 2 |\n",
    "\n",
    "> We grade **understanding and reasoning**, not perfection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19e484",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 0. Setup (Reproducibility)\n",
    "\n",
    "This notebook must run **quickly and reproducibly** for grading.\n",
    "\n",
    "## ✅ Reproducibility requirements\n",
    "- Put all audio files in `./audio/` (relative paths only)\n",
    "- No absolute paths, no cloud mounts\n",
    "- We should be able to download your ZIP and run this notebook top-to-bottom\n",
    "\n",
    "Recommended structure:\n",
    "```\n",
    "HW1/\n",
    "├── HW1_Notebook5_Speech_Production_Segmentation_Variability.ipynb\n",
    "└── audio/\n",
    "    ├── speaker_self/\n",
    "    ├── speaker_2/           (optional but recommended)\n",
    "    └── speaker_3/           (optional)\n",
    "```\n",
    "\n",
    "## Recording requirements (minimum)\n",
    "You must collect at least:\n",
    "### (A) Same-speaker repetition\n",
    "Record yourself saying the sentence **3 times**:\n",
    "- Prompt: **“My name is _____. I am taking a speech AI course.”**\n",
    "Save as:\n",
    "- `./audio/speaker_self/sent_1.wav`\n",
    "- `./audio/speaker_self/sent_2.wav`\n",
    "- `./audio/speaker_self/sent_3.wav`\n",
    "\n",
    "### (B) Sound categories (self)\n",
    "Record these **isolated sounds** (≈1–2 sec each):\n",
    "- Vowels: /a/ and /i/\n",
    "- Fricatives (unvoiced): /s/ and /f/\n",
    "Save as:\n",
    "- `./audio/speaker_self/vowel_a.wav`\n",
    "- `./audio/speaker_self/vowel_i.wav`\n",
    "- `./audio/speaker_self/fric_s.wav`\n",
    "- `./audio/speaker_self/fric_f.wav`\n",
    "\n",
    "### (C) Multi-speaker (recommended)\n",
    "Record the same sentence from **at least one other person** (friend/classmate) OR use a public speech clip.\n",
    "Save as:\n",
    "- `./audio/speaker_2/sent_1.wav`\n",
    "\n",
    "> If you cannot record another person, you must explain why and use a public clip as “speaker_2”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42372e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: WAV loader (reuse from earlier notebooks)\n",
    "def load_wav(path):\n",
    "    \"\"\"Return mono float signal in [-1, 1] and sample rate fs.\"\"\"\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Helpers\n",
    "def play_audio(x, fs):\n",
    "    display(Audio(x, rate=fs))\n",
    "\n",
    "def plot_waveform(x, fs, title, tlim=None):\n",
    "    raise NotImplementedError\n",
    "\n",
    "def plot_spectrogram(x, fs, title, n_fft=1024, win_ms=25, hop_ms=10):\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab99d4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Organize and Load Your Recordings\n",
    "\n",
    "### Task\n",
    "Create a Python dictionary that lists your file paths.\n",
    "\n",
    "**Do not hardcode absolute paths**. Use the provided relative path patterns.\n",
    "\n",
    "Then load each file, print:\n",
    "- fs\n",
    "- duration\n",
    "- min/max amplitude\n",
    "\n",
    "> If sampling rates differ, document what you do (resample or keep separate).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5efd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Provide your paths here\n",
    "paths = {\n",
    "    \"self_sent_1\": \"./audio/speaker_self/sent_1.wav\",\n",
    "    \"self_sent_2\": \"./audio/speaker_self/sent_2.wav\",\n",
    "    \"self_sent_3\": \"./audio/speaker_self/sent_3.wav\",\n",
    "    \"vowel_a\": \"./audio/speaker_self/vowel_a.wav\",\n",
    "    \"vowel_i\": \"./audio/speaker_self/vowel_i.wav\",\n",
    "    \"fric_s\": \"./audio/speaker_self/fric_s.wav\",\n",
    "    \"fric_f\": \"./audio/speaker_self/fric_f.wav\",\n",
    "    # Optional / recommended:\n",
    "    \"speaker2_sent_1\": \"./audio/speaker_2/sent_1.wav\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f16a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load all recordings into a dict: signals[name] = (x, fs)\n",
    "signals = {}\n",
    "# for name, p in paths.items():\n",
    "#     ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c948f0",
   "metadata": {},
   "source": [
    "### Quick sanity check\n",
    "For 2–3 files:\n",
    "- Plot waveform\n",
    "- Plot spectrogram\n",
    "- Play audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c85d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: sanity check (choose a few examples)\n",
    "# name = \"self_sent_1\"\n",
    "# x, fs = signals[name]\n",
    "# plot_waveform(x, fs, f\"{name}: waveform\")\n",
    "# plot_spectrogram(x, fs, f\"{name}: spectrogram\")\n",
    "# play_audio(x, fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6565d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Same-Speaker Variability (Repeatability)\n",
    "\n",
    "You recorded the same sentence 3 times.\n",
    "\n",
    "### Task\n",
    "Compare:\n",
    "- speaking rate (duration)\n",
    "- amplitude range / energy distribution\n",
    "- timing differences (pauses)\n",
    "- spectral patterns\n",
    "\n",
    "You must include:\n",
    "- Overlay plots for the three recordings (time-aligned if possible)\n",
    "- At least one spectrogram comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6fc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract the 3 self recordings\n",
    "# x1, fs1 = signals[\"self_sent_1\"]\n",
    "# x2, fs2 = signals[\"self_sent_2\"]\n",
    "# x3, fs3 = signals[\"self_sent_3\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7a7133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Handle sampling rate mismatch (if any)\n",
    "# Decide: resample to common fs or keep separate and explain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e32f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare durations and basic stats in a small table (markdown or printed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb82d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Overlay waveforms (suggestion: normalize each to same max abs for viewing)\n",
    "# Tip: plot the first N seconds or align to start-of-speech using a simple energy threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3272b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Spectrogram comparison\n",
    "# plot_spectrogram(x1, fs, \"Self sentence 1\")\n",
    "# plot_spectrogram(x2, fs, \"Self sentence 2\")\n",
    "# plot_spectrogram(x3, fs, \"Self sentence 3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054fd6c3",
   "metadata": {},
   "source": [
    "### Observations (Same speaker, repeats)\n",
    "\n",
    "Answer in 10–14 lines:\n",
    "\n",
    "- What stays stable across repeats?\n",
    "- What changes the most (timing, amplitude, articulation clarity)?\n",
    "- Is variability more obvious in waveform or spectrogram? Why?\n",
    "- What does this suggest about “speech as a signal”?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba0cc3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Multi-Speaker Variability\n",
    "\n",
    "Compare your sentence with another speaker (or a public clip).\n",
    "\n",
    "### Task\n",
    "Include:\n",
    "- Waveform and spectrogram comparison\n",
    "- At least one voiced region comparison (pitch differences)\n",
    "- One unvoiced region comparison (fricative/noise differences)\n",
    "\n",
    "> If you use a public clip, specify its source in a markdown cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6239115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load second speaker sentence\n",
    "# xs, fss = signals[\"speaker2_sent_1\"]\n",
    "# plot_waveform(xs, fss, \"Speaker 2: waveform\")\n",
    "# plot_spectrogram(xs, fss, \"Speaker 2: spectrogram\")\n",
    "# play_audio(xs, fss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44057382",
   "metadata": {},
   "source": [
    "### Observations (Across speakers)\n",
    "\n",
    "Answer in 10–14 lines:\n",
    "\n",
    "- Compare pitch range (qualitatively or roughly estimate F0 from harmonics)\n",
    "- Compare speaking rate\n",
    "- Compare spectral envelope (formant regions)\n",
    "- Which differences are likely anatomical vs habitual?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296e9c0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Sound Categories: Vowels vs Fricatives (Voiced vs Unvoiced)\n",
    "\n",
    "You recorded:\n",
    "- Vowels: /a/, /i/\n",
    "- Fricatives: /s/, /f/\n",
    "\n",
    "### Task\n",
    "For each sound:\n",
    "- Plot waveform (zoomed 50–100 ms)\n",
    "- Plot spectrogram\n",
    "- Describe the key differences\n",
    "\n",
    "Focus on:\n",
    "- periodicity vs noise\n",
    "- energy distribution across frequency\n",
    "- voicing cues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf0ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze each isolated sound\n",
    "# for name in [\"vowel_a\", \"vowel_i\", \"fric_s\", \"fric_f\"]:\n",
    "#     x, fs = signals[name]\n",
    "#     plot_waveform(x, fs, f\"{name}: waveform (zoom)\", tlim=(..., ...))\n",
    "#     plot_spectrogram(x, fs, f\"{name}: spectrogram\")\n",
    "#     play_audio(x, fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04a503",
   "metadata": {},
   "source": [
    "### Conceptual questions (Speech production)\n",
    "\n",
    "Answer clearly:\n",
    "\n",
    "1. Why do vowels show a harmonic structure but fricatives often do not?  \n",
    "2. /s/ and /f/ are both unvoiced fricatives. Why do they sound different?  \n",
    "3. How do place and manner of articulation relate to what you see in the spectrogram?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6532f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Segmentation: Words → Syllables → Phones (Approx.)\n",
    "\n",
    "### Goal\n",
    "Take one of your self-sentences and annotate:\n",
    "- Word boundaries (start/end times)\n",
    "- Syllable boundaries (approx.)\n",
    "- Phone-level boundaries for at least **one word** (approx.)\n",
    "\n",
    "You must provide **evidence**:\n",
    "- waveform plot with vertical lines\n",
    "- spectrogram plot with vertical lines\n",
    "- playback of each segmented region\n",
    "\n",
    "> You do not need perfect phonetic labeling. We evaluate reasoning and evidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c666310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Choose the recording to segment\n",
    "seg_name = \"self_sent_1\"\n",
    "# x, fs = signals[seg_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83293898",
   "metadata": {},
   "source": [
    "## 5.1 Define boundaries (in seconds)\n",
    "\n",
    "### Task\n",
    "Create lists of boundary times.\n",
    "\n",
    "Examples:\n",
    "- `word_bounds = [(t0,t1,\"My\"), (t1,t2,\"name\"), ...]`\n",
    "- `syll_bounds = [(t0,t1,\"my\"), (t1,t2,\"name\"), ...]`  (approx.)\n",
    "- `phone_bounds = [(t0,t1,\"m\"), (t1,t2,\"ay\"), ...]`   (approx. for one word)\n",
    "\n",
    "You may use:\n",
    "- waveform inspection\n",
    "- spectrogram inspection\n",
    "- listening + trial-and-error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17953bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill these with your boundary estimates (seconds)\n",
    "word_bounds = [\n",
    "    # (start, end, \"label\"),\n",
    "]\n",
    "\n",
    "syll_bounds = [\n",
    "    # (start, end, \"label\"),\n",
    "]\n",
    "\n",
    "phone_bounds = [\n",
    "    # For ONE chosen word only\n",
    "    # (start, end, \"label\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot waveform with boundaries\n",
    "# - Overlay word boundaries in one plot\n",
    "# - Overlay syllable boundaries in another plot\n",
    "# - Overlay phone boundaries for one word (zoomed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba3935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot spectrogram with boundaries\n",
    "# Use vertical lines (plt.axvline) at boundary times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Play segments\n",
    "# For each word in word_bounds:\n",
    "#   extract and play that segment\n",
    "# For each syllable in syll_bounds:\n",
    "#   extract and play\n",
    "# For phone_bounds (one word):\n",
    "#   extract and play\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2d0666",
   "metadata": {},
   "source": [
    "### Observations (Segmentation & coarticulation)\n",
    "\n",
    "Answer in 12–16 lines:\n",
    "\n",
    "- Which boundaries were easy to identify? Which were hard? Why?\n",
    "- Where do you see coarticulation (smooth transitions rather than clear breaks)?\n",
    "- Give one example where the phone boundary is ambiguous, and explain why.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83046e6c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Mini-Analysis: Voiced vs Voiceless Regions in a Sentence\n",
    "\n",
    "### Task\n",
    "Pick two short regions from your sentence:\n",
    "- one clearly voiced (vowel-like)\n",
    "- one clearly voiceless (fricative-like or unvoiced consonant)\n",
    "\n",
    "For each region:\n",
    "- plot waveform (zoom)\n",
    "- plot spectrum or spectrogram\n",
    "- explain differences in terms of production and acoustics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b85f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define two regions (seconds)\n",
    "voiced_region = (None, None)\n",
    "voiceless_region = (None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b88b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract, plot, and play the two regions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf6c4b",
   "metadata": {},
   "source": [
    "### Conceptual explanation (Voicing)\n",
    "\n",
    "Write 8–12 lines:\n",
    "\n",
    "- How does voicing appear in waveform and spectrogram?\n",
    "- What cues did you use to label a region as voiced vs voiceless?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba68dd4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Summary: Key Takeaways\n",
    "\n",
    "Write 8–12 lines:\n",
    "\n",
    "- What did you learn about speech variability (same speaker vs different speaker)?\n",
    "- What did segmentation teach you about coarticulation?\n",
    "- How did speech production theory help you interpret your plots?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c253e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8. Reflection (Mandatory)\n",
    "\n",
    "Write thoughtful answers (be specific):\n",
    "\n",
    "1. What did you learn about your own speech signal that surprised you?  \n",
    "2. What was the hardest part: recording, organizing files, variability analysis, or segmentation? Why?  \n",
    "3. Which visualization helped most (waveform vs spectrogram vs playback)?  \n",
    "4. If you could redo one part, what would you do differently?  \n",
    "5. What is one question you now want to explore further (e.g., pitch tracking, formant estimation, phoneme classification)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884c30a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 9. AI Use Disclosure (Required)\n",
    "\n",
    "If you used any AI tools (including ChatGPT), briefly describe:\n",
    "- What you used it for (e.g., debugging, concept clarification)\n",
    "- What you wrote/changed yourself\n",
    "\n",
    "*(If you did not use AI, write “No AI tools used.”)*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
